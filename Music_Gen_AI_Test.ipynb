{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "from music21 import *\n",
    "import os \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch import tensor\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import tensorflow as tf\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from ast import literal_eval\n",
    "\n",
    "notes_df = pd.read_csv ('Dataset/notes.csv')\n",
    "test_df = pd.read_csv ('Dataset/testset.csv')\n",
    "\n",
    "data_test = test_df[['x_test','future']].to_numpy()\n",
    "\n",
    "x_test_string = data_test[:,0]\n",
    "y_test_string = data_test[:,1]\n",
    "x_test = []\n",
    "y_test = []\n",
    "for i in x_test_string:\n",
    "\n",
    "    b = \"[]\\n\"\n",
    "    for char in b:\n",
    "        i = i.replace(char, \"\")\n",
    "    input_x_test = [int(j) for j in i.split()]\n",
    "    x_test.append(input_x_test)\n",
    "\n",
    "for i in y_test_string:\n",
    "\n",
    "    b = \"[]\\n\"\n",
    "    for char in b:\n",
    "        i = i.replace(char, \"\")\n",
    "    input_y_test = [int(j) for j in i.split()]\n",
    "    y_test.append(input_y_test)\n",
    "x_test = np.array(x_test)\n",
    "y_test = np.array(y_test)\n",
    "    \n",
    "\n",
    "\n",
    "notes_ = notes_df.to_numpy()[:,1]\n",
    "unique_notes = dict(enumerate(notes_.flatten(), 0))\n",
    "# unique_notes = {value : key for (key, value) in unique_notes_reverse.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from MusicDataset import *\n",
    "test_set = MusicDataset(x_test,y_test)\n",
    "testloader = torch.utils.data.DataLoader(test_set, batch_size=1,\n",
    "                                         shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequence(\n",
      "  (embedding): Embedding(173, 100)\n",
      "  (lstm): LSTM(100, 256, num_layers=3, batch_first=True)\n",
      "  (linear1): Linear(in_features=256, out_features=128, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (linear2): Linear(in_features=128, out_features=128, bias=True)\n",
      "  (softmax): Softmax(dim=None)\n",
      "  (linear3): Linear(in_features=128, out_features=173, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from Models import Wavenet, LSTM\n",
    "\n",
    "Net = torch.load('Trained_Model/model.pth', map_location=torch.device('cpu'))\n",
    "print(Net)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import torch\n",
    "#print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Accuracy : \n",
      " correct predictions  : 8004 \n",
      " total predictions : 64112 \n",
      " Testing Accuracy : 12.484402295982031 \n",
      " ------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "total_preds = 0\n",
    "correct_preds = 0\n",
    "future_preds = 8\n",
    "for i, data in enumerate(testloader, 0):\n",
    "\n",
    "    input , label = data\n",
    "    cumm_output = torch.zeros(0,len(unique_notes)).to(device)\n",
    "    cumm_label  = np.array([],dtype=int)\n",
    "    for k in range(future_preds):\n",
    "        output = Net(input.to(device),input.shape[0])\n",
    "        cumm_output = torch.cat((cumm_output,output))\n",
    "        cumm_label = np.concatenate((cumm_label,label[:,k]))\n",
    "        next_preds = np.argmax(output.cpu().detach().numpy(),axis=1)\n",
    "        total_preds += input.shape[0]\n",
    "        correct_preds += torch.sum(torch.argmax(output,1) == label[:,k].to(device))\n",
    "        input = input.cpu().detach().numpy()\n",
    "        input = torch.from_numpy(np.array([np.append(j,next_preds[ind]) \n",
    "                                               for ind,j in enumerate(input)])[:,1:]) \n",
    "test_acc =  float(correct_preds)/float(total_preds) *100 \n",
    "testreport =\"Testing Accuracy : \\n correct predictions  : {} \\n total predictions : {} \\n Testing Accuracy : {} \\n ------------------------\\n\".format(correct_preds,total_preds,test_acc)\n",
    "print(testreport)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taking the seed tune as follows:\n",
      "[124  38 124 151  38 124  93 158 142 142 158  93 124  38  78 147 143  13\n",
      " 143  13 143  13 143  13 112 143  13 155  27 141 120  78]\n",
      "Taking the seed tune as follows:\n",
      "[ 17 102  39   8 102 130 117   6 171 135  91 117 135  17  39   8 102 163\n",
      "  97   4 108 125  39 107 146 108  45 163   6  29 146  45]\n",
      "Taking the seed tune as follows:\n",
      "[171 171 116  56  40 132 129 116 122  56 159   5 171   5 171   5 171  98\n",
      " 171 159  50 109 109 109 109 109 109 109  73  50 109 109]\n",
      "Taking the seed tune as follows:\n",
      "[  5  50 129  29  50 113   9  21   9  97  68  62   9 115 125   9  21 125\n",
      "   9  97  68 146   9 163  80  39  22  97  80   6  16  80]\n",
      "Taking the seed tune as follows:\n",
      "[ 45 149  29  12  45  29 149  45  29  12  45  45 149  29 130  12 117 108\n",
      " 149   4 130  12  45  29   7 106  41  29 106   7  29   4]\n",
      "Taking the seed tune as follows:\n",
      "[ 81  43 115  43 115 128  81 128 115 128 115  81 115 115  43  81  43 115\n",
      "  43 115  43  20 140 115 172  43 115 140  43  20  43 115]\n",
      "Taking the seed tune as follows:\n",
      "[ 29  66 145 117  29  43 125  34  75  29 108  34 135  16  96  59  45 130\n",
      "  96  29 145 129 111  29 117  70 111  29 145 129 111 108]\n",
      "Taking the seed tune as follows:\n",
      "[103 135 157 162  94 135 157 162  94 112 157  98  11 140   2 112 121   8\n",
      " 121  44 145 140  32 155 134 157 162  94  17   8  85 157]\n",
      "Taking the seed tune as follows:\n",
      "[172  54  91 172 124  34 151 108 124  34 151 108 128  45   0  91 128  45\n",
      "   0  91   0   4  51 117   0   4  51 117  54 146  51   4]\n",
      "Taking the seed tune as follows:\n",
      "[ 59 151  38  54 153 142   7 142  54  41  38 151  41 120  59 128 141   0\n",
      " 153  51 143 112   7 172  43 117  41 108   4  41 130  59]\n"
     ]
    }
   ],
   "source": [
    "# Time to generate some Music!!!\n",
    "import random\n",
    "from Dataset import midi_helper \n",
    "for j in range(10):\n",
    "    index = random.randint(0, len(x_test))\n",
    "    print(\"Taking the seed tune as follows:\")\n",
    "    print(x_test[index])\n",
    "    tune = x_test[index]\n",
    "    input = np.empty((1, 32), dtype=int)\n",
    "    input[0] = tune\n",
    "    input = torch.from_numpy(input)\n",
    "    next_preds = 64\n",
    "    for i in range(next_preds):\n",
    "        output = Net(input.to(device), input.shape[0])\n",
    "        next_preds = np.argmax(output.cpu().detach().numpy(), axis=1)\n",
    "        input = input.cpu().detach().numpy()\n",
    "        input = torch.from_numpy(np.array([np.append(j, next_preds[ind]) \n",
    "                                           for ind, j in enumerate(input)])[:, 1:])\n",
    "        tune = np.insert(tune, -1, next_preds[0])\n",
    "    tune = [unique_notes[i] for i in tune]\n",
    "    path = './Outputs/music'+str(j)+'.midi'\n",
    "    midi_helper.convert_to_midi(tune)  # Remove the path argument\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
